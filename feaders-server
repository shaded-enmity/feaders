#!/usr/bin/python -tt
# vim: set fileencoding=utf-8
# /ˈfed.ərs/ Pavel Odvody <podvody@redhat.com> 2015 - MIT License
from flask import Flask, redirect, request, render_template, url_for
from feader.repohandler import Repositories, RepoType, RepoHandler
from feader.sqlhandler import SqlHandler
from feader.enums import PREFIXES, CACHE_FOLDER
from feader.htauth import requires_auth
from pwd import getpwnam, getpwuid
import argparse
import glob
import json
import os
import sys

app = Flask(__name__, 
            template_folder='/usr/share/feaders/templates', 
            static_folder='/usr/share/feaders/static'
      )

def get_args():
  arch = request.args.get('arch', Repositories.DEFAULT_ARCH)
  name = request.args.get('name', Repositories.DEFAULT_NAME)
  release =  request.args.get('release', Repositories.DEFAULT_RELEASE)
  return arch, name, release

@app.route("/get_packages", methods=['POST'])
def get_includes():
  verbose = 'verbose' in request.args

  arch, name, release = get_args()
  base = os.path.join(CACHE_FOLDER, name, release, arch)

  # glob for db files, the glob will actually match multiple files
  # only for CentOS repositories, where the content is split 
  # between 'os' repo and 'updates' repo. While this is true for
  # Fedora repositories too (fedora.repo, fedora-updates.repo),
  # in Fedora the content of both of these repos is incremental, while
  # in CentOS ... excremental? :D What I mean is that 'os' doesn't contain
  # /usr/bin/python while 'updates' does, and there's more examples like this.
  sql = SqlHandler(glob.glob(os.path.join(base, 'files*.sqlite')),
                   glob.glob(os.path.join(base, 'primary*.sqlite')), 
                   verbose=verbose)

  if 'raw_includes' in request.form:
    # raw request from the HTML form
    # when in include mode we prepend include search paths before each element
    include_mode = False if 'include_mode' not in request.form else True
    includes = filter(None, request.form['raw_includes'].splitlines())
    if include_mode:
      # combine the includes and prefixes
      includes = [os.path.join(p, i) for i in includes for p in PREFIXES]
    return '\n'.join(sql.process_includes(arch, includes))
  elif 'includes' in request.form:
    # JSON request, includes contains an array of include files to search for
    includes = json.loads(request.form['includes'])
    return json.dumps(sql.process_includes(arch, includes))
  else:
    return "Error, case unhandled"

@app.route("/add_cache")
@requires_auth
def add_cache():
  return render_template('add_cache.html')

@app.route("/refresh_cache")
@requires_auth
def refresh_cache():
  print('started caching')
  rh = RepoHandler(CACHE_FOLDER)

  # get cache arguments
  arch, name, release = get_args()
  typ = RepoType.from_string(
    request.args.get('type', 'fedora')
  )

  # create cache
  caches = rh.create_repo_cache(
    name, release, arch, typ
  )

  if app.debug:
    # print the created caches in debug mode
    print("\n".join(caches))

  return redirect("/")

@app.route("/")
def index():
  seen, kv = set(), []
  # find the unique caches that we can use for searching
  for root, folder, files in os.walk(CACHE_FOLDER):
    for f in files:
      if f.startswith('primary') and f.endswith('sqlite'):
        cache_root = os.path.relpath(root, CACHE_FOLDER)
        kvs = zip(('name', 'release', 'arch'), cache_root.split('/')[:3])
        as_str = str(kvs)
        if as_str not in seen:
          seen.add(as_str)
          kv.append(dict(kvs))
  return render_template('index.html', cached=kv)

def __ensure_cache_folder(folder):
  parts = [p if p else '/' for p in folder.split(os.path.sep)]
  results = []
  for i, p in enumerate(parts):
    try:
      os.mkdir(os.path.abspath(os.path.sep.join(parts[:i+1])))
      results.append(True)
    except OSError as e:
      if e.errno == os.errno.EACCES:
        print('permission denied for {}'.format(e.filename))
      results.append(e.errno == os.errno.EEXIST and os.path.isdir(e.filename))
  return all(results)

def __drop_privilege(to, pidfile):
  uid, numeric = to, False

  # try convert to numeric
  try:
    uid = int(to, 10)
    numeric = True
  except:
    pass

  # get pw structure
  if not numeric:
    uid = getpwnam(uid)
  else:
    uid = getpwuid(uid)

  with open(pidfile, 'w+') as p:
    # own pidfile and cache folder as target user
    os.chown(pidfile, uid.pw_uid, uid.pw_gid)
    os.chown(CACHE_FOLDER, uid.pw_uid, uid.pw_gid)

    # set {e}uid/{e}gid
    os.setgid(uid.pw_gid)
    os.setegid(uid.pw_gid)
    os.setuid(uid.pw_uid)
    os.seteuid(uid.pw_uid)

    # quit parent ASAP
    pid = os.fork()
    if pid > 0:
      p.write(str(pid))
      sys.exit(0)

if __name__ == "__main__":
  ap = argparse.ArgumentParser()
  ap.add_argument('-c', '--cache-folder', default=CACHE_FOLDER, help='path to cache folder')
  ap.add_argument('-i', '--pidfile', default='/var/run/feaders-server.pid', help='path to pid file')
  ap.add_argument('-p', '--port', default=5000, type=int, help='port at which to listen')
  ap.add_argument('-a', '--address', default='0.0.0.0', help='address at which to listen')
  ap.add_argument('-d', '--drop-priv', default=False, help='drop privileges to this user/uid', nargs='?', const=False)
  args = ap.parse_args()

  CACHE_FOLDER = args.cache_folder

  if not __ensure_cache_folder(CACHE_FOLDER):
    print("Cache folder inaccessible: {}".format(CACHE_FOLDER))
    sys.exit(1)

  if args.drop_priv:
    __drop_privilege(args.drop_priv, args.pidfile)

  app.run(debug=True, port=args.port, host=args.address)
